{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data before start using techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from unidecode import unidecode\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from spacy.lang.pt.stop_words import STOP_WORDS\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar_texto(text):\n",
    "    \n",
    "    # Colocando todas as letras do texto em caixa baixa:\n",
    "    text = text.lower()\n",
    "    # Excluindo citações com @:\n",
    "    text = re.sub('@[^\\s]+', '', text)\n",
    "    # Excluindo acentuação das palavras:\n",
    "    text = unidecode(text)\n",
    "    # Excluindo html tags, como <strong></strong>:\n",
    "    text = re.sub('<[^<]+?>','', text)\n",
    "    # Excluindo os números:\n",
    "    text = ''.join(c for c in text if not c.isdigit())\n",
    "    # Excluindo URL's:\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))', '', text)\n",
    "    # Excluindo pontuação:\n",
    "    text = ''.join(c for c in text if c not in punctuation)\n",
    "    \n",
    "    # Retornando o texto tratado tokenizado:\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ability', 'across', 'affenpinscher', 'afghan', 'afghanistan', 'africa', 'african', 'africanis', 'also', 'among', 'and', 'appearance', 'are', 'as', 'at', 'balkh', 'baluchi', 'barakzai', 'bred', 'breed', 'by', 'charming', 'coat', 'cold', 'curl', 'dari', 'distinctive', 'distinguished', 'dog', 'end', 'fast', 'features', 'fine', 'for', 'found', 'gained', 'galanday', 'germany', 'has', 'have', 'hound', 'in', 'incorrectly', 'is', 'its', 'kabul', 'known', 'landrace', 'like', 'local', 'lovers', 'monkey', 'mountains', 'name', 'names', 'of', 'or', 'originated', 'other', 'pashto', 'personality', 'pinscher', 'popularity', 'ring', 'run', 'sag', 'selectively', 'shalgar', 'sighthounds', 'silky', 'sized', 'small', 'sometimes', 'southern', 'spay', 'tail', 'terrier', 'that', 'the', 'they', 'thick', 'this', 'to', 'toy', 'turn', 'tāzī', 'tāžī', 'unique', 'well', 'with', 'worldwide', 'تازی', 'تاژي', 'سپی', 'سگ']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Multiple documents\n",
    "text = [\"The Affenpinscher, also known as the Monkey Terrier, is a small-sized terrier-like toy Pinscher breed of dog that originated in Germany. With a distinctive appearance and charming personality, the Affenpinscher has gained popularity among dog lovers worldwide.\\n\", \"The Afghan Hound is a Hound distinguished by its thick, fine, silky coat, and a tail with a ring curl at the end. The breed is selectively bred for its unique features in the cold mountains of Afghanistan. Its local name is Tāžī Spay (Pashto: تاژي سپی) or Sag-e Tāzī (Dari: سگ تازی). Other names for this breed are Tāzī, Balkh Hound, Baluchi Hound, Barakzai Hound, Shalgar Hound, Kabul Hound, Galanday Hound or sometimes incorrectly African Hound. As with other sighthounds, they have the ability to run fast and turn well.\\n\", \"The Africanis is a dog landrace found across southern Africa.[1]\\n\"]\n",
    "\n",
    "# create the transform\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "\n",
    "# summarize\n",
    "print(sorted(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
